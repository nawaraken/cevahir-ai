import os
import json
import pytest
from tokenizer_management.vocab.vocab_updater import VocabUpdater, VocabUpdateError
from tokenizer_management.config import VOCAB_PATH

# === Fixture ===
@pytest.fixture
def sample_vocab():
    return {
        "<PAD>": 0,
        "<UNK>": 1,
        "<EOS>": 2,
        "<BOS>": 3,
        "merhaba": 4,
        "dÃ¼nya": 5
    }

@pytest.fixture
def vocab_updater(sample_vocab):
    return VocabUpdater(sample_vocab.copy())

@pytest.fixture(autouse=True)
def setup_and_teardown_vocab():
    backup_path = VOCAB_PATH + ".bak"
    if os.path.exists(VOCAB_PATH):
        os.rename(VOCAB_PATH, backup_path)

    yield

    if os.path.exists(backup_path):
        if os.path.exists(VOCAB_PATH):
            os.remove(VOCAB_PATH)
        os.rename(backup_path, VOCAB_PATH)


# === ğŸ§ª TESTLER ===

# âœ… BaÅŸarÄ±yla yeni token ekleniyor mu?
def test_add_new_token(vocab_updater):
    vocab_updater.add_token("cevahir")
    assert "cevahir" in vocab_updater.vocab
    assert vocab_updater.vocab["cevahir"] == 6

# âœ… Mevcut token tekrar eklendiÄŸinde warning veriyor mu?
def test_add_existing_token(vocab_updater, caplog):
    vocab_updater.add_token("merhaba")
    assert "Token zaten mevcut" in caplog.text

# âœ… Token ID manuel olarak verilebiliyor mu?
def test_add_token_with_specific_id(vocab_updater):
    vocab_updater.add_token("cevahir", 10)
    assert vocab_updater.vocab["cevahir"] == 10

# âœ… Token ID Ã§akÄ±ÅŸma hatasÄ± kontrolÃ¼
def test_add_token_id_conflict(vocab_updater):
    with pytest.raises(VocabUpdateError, match="Token ID Ã§akÄ±ÅŸmasÄ±"):
        vocab_updater.add_token("cevahir", 1)

# âœ… Mevcut token ID gÃ¼ncellemesi baÅŸarÄ±lÄ± mÄ±?
def test_update_existing_token_id(vocab_updater):
    vocab_updater.update_token("merhaba", 10)
    assert vocab_updater.vocab["merhaba"] == 10

# âœ… Olmayan token gÃ¼ncellemesi hata fÄ±rlatÄ±yor mu?
def test_update_nonexistent_token(vocab_updater):
    with pytest.raises(VocabUpdateError, match="Token bulunamadÄ±"):
        vocab_updater.update_token("cevahir", 10)

# âœ… GÃ¼ncellemede token ID Ã§akÄ±ÅŸmasÄ± hatasÄ± veriyor mu?
def test_update_token_id_conflict(vocab_updater):
    with pytest.raises(VocabUpdateError, match="Token ID Ã§akÄ±ÅŸmasÄ±"):
        vocab_updater.update_token("merhaba", 1)

# âœ… BaÅŸarÄ±yla token siliniyor mu?
def test_remove_existing_token(vocab_updater):
    vocab_updater.remove_token("merhaba")
    assert "merhaba" not in vocab_updater.vocab

# âœ… Silinemeyen token iÃ§in uyarÄ± veriliyor mu?
def test_remove_nonexistent_token(vocab_updater, caplog):
    vocab_updater.remove_token("cevahir")
    assert "Token bulunamadÄ±ÄŸÄ± iÃ§in silinemedi" in caplog.text

# âœ… Vocab dosyasÄ± baÅŸarÄ±yla kaydediliyor mu?
def test_save_vocab(vocab_updater):
    vocab_updater.add_token("cevahir")
    vocab_updater.save_vocab()

    assert os.path.exists(VOCAB_PATH)

    with open(VOCAB_PATH, "r", encoding="utf-8") as file:
        data = json.load(file)
        assert data["cevahir"] == 6

# âœ… Dosya izin hatasÄ± doÄŸru ÅŸekilde yakalanÄ±yor mu?
def test_save_vocab_permission_error(vocab_updater, mocker):
    mocker.patch("builtins.open", side_effect=PermissionError("Ä°zin hatasÄ±"))

    with pytest.raises(VocabUpdateError, match="Vocab dosyasÄ± yazÄ±lamadÄ±"):
        vocab_updater.save_vocab()

# âœ… Vocab boyutunu doÄŸru dÃ¶ndÃ¼rÃ¼yor mu?
def test_get_vocab_size(vocab_updater):
    size = vocab_updater.get_vocab_size()
    assert size == 6  # sample_vocab'daki baÅŸlangÄ±Ã§ tokenleri sayÄ±sÄ±
