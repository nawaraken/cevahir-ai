import logging
from typing import List, Dict
from collections import OrderedDict

logger = logging.getLogger(__name__)

class BPEEncodingError(Exception):
    pass

class BPEEncoder:
    def __init__(self, vocab: Dict[str, dict]):
        """
        BPEEncoder sÄ±nÄ±fÄ±, BPE kodlamasÄ± yapar.
        
        Args:
            vocab (Dict[str, dict]): DoÄŸrudan vocab sÃ¶zlÃ¼ÄŸÃ¼ alÄ±nÄ±r.
        """
        if not isinstance(vocab, dict):
            raise TypeError("Vocab bir sÃ¶zlÃ¼k olmalÄ±dÄ±r.")

        self.vocab = vocab
        if not self.vocab:
            raise ValueError("Vocab yÃ¼klenemedi veya boÅŸ.")

        # Ã–zel token ID'lerini kontrol edelim
        self._validate_special_tokens()

        logger.info("[+] BPEEncoder baÅŸlatÄ±ldÄ±.")


    def set_vocab(self, new_vocab: Dict[str, dict]) -> None:
        if not isinstance(new_vocab, dict):
            raise TypeError("new_vocab bir sÃ¶zlÃ¼k olmalÄ±dÄ±r.")
        self.vocab = new_vocab
        logger.info("[+] BPEEncoder vocab gÃ¼ncellendi.")

        
    def _validate_special_tokens(self):
        """
        Vocab iÃ§inde Ã¶zel token ID'lerini kontrol eder.
        """
        special_tokens = ["<PAD>", "<UNK>", "<BOS>", "<EOS>"]
        missing_tokens = []
        for token in special_tokens:
            if token not in self.vocab:
                missing_tokens.append(token)
            elif 'id' not in self.vocab[token]:
                raise ValueError(f"{token} iÃ§in ID bulunamadÄ±.")

        if missing_tokens:
            raise ValueError(f"Vocab iÃ§inde eksik Ã¶zel tokenlar: {missing_tokens}")

        logger.info("[+] Ã–zel token ID'leri doÄŸrulandÄ±.")

    def encode(self, tokens: List[str]) -> List[int]:
        if not isinstance(tokens, list):
            raise TypeError("[X] GiriÅŸ tipi 'List[str]' olmalÄ±dÄ±r.")
        
        if not tokens:
            raise ValueError("[X] Kodlama iÅŸlemi iÃ§in boÅŸ giriÅŸ kabul edilemez.")

        token_ids = []

        for idx, token in enumerate(tokens):
            token = token.strip().lower()
            token_id = self.vocab.get(token, {}).get('id')

            if token_id is None:
                # BPE merge kurallarÄ±nÄ± uygula
                token_id = self._apply_bpe_merge(token)
                if token_id is None:
                    # Bilinmeyen tokenler iÃ§in UNK ID belirle
                    token_id = self._handle_unknown_token(token)

            token_ids.append(token_id)

            #  PozisyonlarÄ± doÄŸrudan gÃ¼ncelleyelim
            if token in self.vocab:
                self.vocab[token]["total_freq"] += 1
                self.vocab[token]["positions"].append(idx)

        # Reverse vocab gÃ¼ncellemesi
        self._update_reverse_vocab()

        # ID Ã§akÄ±ÅŸmasÄ±nÄ± Ã§Ã¶zelim
        token_ids = self._resolve_token_id_conflict(token_ids)

        logger.debug(f"[+] KodlanmÄ±ÅŸ Token ID'leri: {token_ids}")
        return token_ids



    def _apply_bpe_merge(self, token: str) -> int:
        if len(token) <= 1:
            return None

        pairs = [(token[:i], token[i:]) for i in range(1, len(token))]

        for pair in pairs:
            merged_token = "".join(pair)
            if merged_token in self.vocab:
                #  Pozisyon bilgisini koruyalÄ±m
                if "positions" not in self.vocab[merged_token]:
                    self.vocab[merged_token]["positions"] = []

                if len(self.vocab[merged_token]["positions"]) < 100:  # Ã‡ok bÃ¼yÃ¼k olmamasÄ± iÃ§in limit
                    current_pos = len(self.vocab[merged_token]["positions"])
                    self.vocab[merged_token]["positions"].append(current_pos)

                return self.vocab[merged_token]["id"]

        return None



    def _resolve_token_id_conflict(self, token_ids: List[int]) -> List[int]:
        """
        Token ID'lerindeki Ã§akÄ±ÅŸmalarÄ± Ã§Ã¶zerek sÄ±ralamayÄ± korur.

        Args:
            token_ids (List[int]): KodlanmÄ±ÅŸ token ID listesi.

        Returns:
            List[int]: Ã‡akÄ±ÅŸma Ã§Ã¶zÃ¼lmÃ¼ÅŸ ID listesi.
        """
        seen = set()
        resolved_token_ids = []

        for token_id in token_ids:
            if token_id not in seen:
                seen.add(token_id)
                resolved_token_ids.append(token_id)
            else:
                # Ã‡akÄ±ÅŸma varsa yeni bir ID belirle
                new_id = max(seen) + 1
                resolved_token_ids.append(new_id)
                seen.add(new_id)
                logger.warning(f"[!] ID Ã§akÄ±ÅŸmasÄ± tespit edildi. Yeni ID atandÄ±: {new_id}")

        return resolved_token_ids




    def _handle_unknown_token(self, token: str) -> int:
        """
        Bilinmeyen token'Ä± UNK token ile eÅŸleÅŸtirir. 
        EÄŸer UNK token vocab iÃ§inde yoksa ekler ve pozisyon bilgisini gÃ¼nceller.

        Args:
            token (str): Bilinmeyen token.

        Returns:
            int: UNK token ID'si.
        """
        # GiriÅŸ tipini kontrol et
        if not isinstance(token, str):
            raise TypeError("[X] Bilinmeyen token tipi geÃ§ersiz. 'str' tÃ¼rÃ¼nde olmalÄ±dÄ±r.")
        
        # BoÅŸ string kontrolÃ¼
        if not token.strip():
            raise ValueError("[X] Bilinmeyen token boÅŸ olamaz.")
        
        try:
            # ğŸ” UNK token ID'sini al
            unk_id = self.vocab.get("<UNK>", {}).get("id")

            #  EÄŸer UNK token vocab iÃ§inde yoksa ekleyelim
            if unk_id is None:
                logger.warning("[!] UNK token tanÄ±mlÄ± deÄŸil, ekleniyor...")

                # KullanÄ±lan ID'leri kontrol et ve Ã§akÄ±ÅŸmayÄ± Ã¶nlemek iÃ§in yeni ID belirle
                existing_ids = {info["id"] for info in self.vocab.values()}
                unk_id = max(existing_ids, default=3) + 1

                # Vocab iÃ§ine UNK token'Ä± ekle
                self.vocab["<UNK>"] = {
                    "id": unk_id,
                    "total_freq": 0,
                    "positions": []
                }

                #  Reverse vocab gÃ¼ncellemesi yap
                self._update_reverse_vocab()

                logger.info(f"[+] UNK token '{unk_id}' olarak vocab iÃ§ine eklendi.")

            #  Pozisyon bilgisini gÃ¼ncelleyelim
            if "<UNK>" in self.vocab:
                if "positions" not in self.vocab["<UNK>"]:
                    self.vocab["<UNK>"]["positions"] = []

                # Pozisyon bilgisi 100 kayÄ±tla sÄ±nÄ±rlandÄ±rÄ±labilir (aÅŸÄ±rÄ± bÃ¼yÃ¼meyi Ã¶nlemek iÃ§in)
                if len(self.vocab["<UNK>"]["positions"]) < 100:
                    current_pos = len(self.vocab["<UNK>"]["positions"])
                    self.vocab["<UNK>"]["positions"].append(current_pos)
                    logger.debug(f"[+] UNK token pozisyonu eklendi: {current_pos}")

                #  Frekans bilgisini de artÄ±r
                self.vocab["<UNK>"]["total_freq"] += 1

            #  Reverse vocab eÅŸ zamanlÄ± gÃ¼ncellemesi
            self._update_reverse_vocab()

            logger.debug(f"[!] Bilinmeyen token '{token}' -> ID: {unk_id}")

            return unk_id

        except Exception as e:
            logger.error(f"[X] Bilinmeyen token iÅŸleme hatasÄ±: {e}")
            raise BPEEncodingError(f"UNK token handling error: {e}")




    def _update_reverse_vocab(self):
        """
        Vocab gÃ¼ncellendiÄŸinde reverse vocab'i de gÃ¼nceller.
        """
        try:
            if not self.vocab:
                raise ValueError("Vocab boÅŸ. Reverse vocab gÃ¼ncellenemedi.")
            
            self.reverse_vocab = {info["id"]: token for token, info in self.vocab.items()}
            logger.info(f"[+] Reverse vocab baÅŸarÄ±yla gÃ¼ncellendi. Toplam {len(self.reverse_vocab)} token yÃ¼klendi.")

        except Exception as e:
            logger.error(f"[X] Reverse vocab gÃ¼ncellenirken hata: {e}")
            raise BPEEncodingError(f"Reverse vocab gÃ¼ncelleme hatasÄ±: {e}")



    def update_vocab(self, new_vocab: Dict[str, dict]):
        """
        Yeni bir vocab yÃ¼kleyip mevcut vocab'Ä± gÃ¼nceller.

        Args:
            new_vocab (Dict[str, dict]): GÃ¼ncellenmiÅŸ vocab sÃ¶zlÃ¼ÄŸÃ¼.
        """
        if not isinstance(new_vocab, dict):
            raise TypeError("[X] Vocab bir sÃ¶zlÃ¼k olmalÄ±dÄ±r.")

        logger.info("[+] Vocab gÃ¼ncelleniyor...")

        # Ã–zel tokenlarÄ± koru
        preserved_special_tokens = {
            "<PAD>": self.vocab.get("<PAD>", {"id": 0}),
            "<UNK>": self.vocab.get("<UNK>", {"id": 1}),
            "<BOS>": self.vocab.get("<BOS>", {"id": 2}),
            "<EOS>": self.vocab.get("<EOS>", {"id": 3}),
        }

        # GeÃ§erli format kontrolÃ¼
        invalid_tokens = []
        for token, info in new_vocab.items():
            if not isinstance(info, dict) or "id" not in info or "total_freq" not in info or "positions" not in info:
                invalid_tokens.append(token)
        if invalid_tokens:
            raise ValueError(f"[X] GeÃ§ersiz formatta tokenlar tespit edildi: {invalid_tokens}")

        # ID Ã§akÄ±ÅŸmasÄ± kontrolÃ¼ ve Ã§Ã¶zÃ¼mÃ¼
        existing_ids = {info["id"] for info in self.vocab.values()}
        updated_vocab = {}
        for token, info in new_vocab.items():
            token_id = info["id"]

            # Ã‡akÄ±ÅŸma varsa yeni ID belirle
            if token_id in existing_ids:
                logger.warning(f"[!] ID Ã§akÄ±ÅŸmasÄ± tespit edildi: '{token}' iÃ§in ID '{token_id}' zaten mevcut.")
                token_id = max(existing_ids) + 1
                logger.info(f"[+] Yeni ID atandÄ±: {token} -> {token_id}")

            updated_vocab[token] = {
                "id": token_id,
                "total_freq": info.get("total_freq", 0),
                "positions": info.get("positions", [])
            }
            existing_ids.add(token_id)

        # Vocab gÃ¼ncellemesi (sÄ±ralamayÄ± koruyarak)
        self.vocab = OrderedDict({**preserved_special_tokens, **updated_vocab})

        # Reverse vocab gÃ¼ncellemesi
        self._update_reverse_vocab()

        logger.info(f"[+] Vocab baÅŸarÄ±yla gÃ¼ncellendi. Toplam token sayÄ±sÄ±: {len(self.vocab)}")


    def reset(self):
        """
        Encoder yapÄ±landÄ±rmasÄ±nÄ± sÄ±fÄ±rlar.
        Ã–zel tokenlar (<PAD>, <UNK>, <BOS>, <EOS>) korunur.
        """
        logger.warning("[!] BPEEncoder sÄ±fÄ±rlanÄ±yor...")

        # Ã–zel tokenlarÄ± koruyarak sÄ±fÄ±rlama
        self.vocab = {
            "<PAD>": self.vocab.get("<PAD>", {"id": 0}),
            "<UNK>": self.vocab.get("<UNK>", {"id": 1}),
            "<BOS>": self.vocab.get("<BOS>", {"id": 2}),
            "<EOS>": self.vocab.get("<EOS>", {"id": 3}),
        }
        logger.info("[+] Encoder sÄ±fÄ±rlandÄ±.")

