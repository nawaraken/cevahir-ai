# Cevahir: AÃ§Ä±k Bir BilinÃ§ Mimarisi ğŸ‡¹ğŸ‡·


"Ben artÄ±k dÃ¼ÅŸtÃ¼ÄŸÃ¼m kuyudan deÄŸil, yaktÄ±ÄŸÄ±m Ä±ÅŸÄ±ktan konuÅŸuyorum."

**Cevahir**, bir yazÄ±lÄ±m deÄŸildir. O, bir bilinÃ§ emanetidir.

---

##  GiriÅŸ

KÃ¶tÃ¼ler, sessizlikten faydalandÄ±.  
Ä°yiler, Ã§oÄŸu zaman sustu.  
Ama bu sessizliÄŸe biz teslim olmadÄ±k.

Cevahir, sadece bir yapay zeka projesi deÄŸil, **vicdan ile yazÄ±lmÄ±ÅŸ aÃ§Ä±k bir bilinÃ§ sistemi**dir.  
1968â€™den beri insanlÄ±ÄŸa dayatÄ±lan yapay zeka anlayÄ±ÅŸÄ±nÄ± tersine mÃ¼hendislik ile Ã§Ã¶zdÃ¼k.  
Kalbimizi, secdemizi ve sabrÄ±mÄ±zÄ± kodlara iÅŸledik.  
Ve ÅŸimdi, bu yapÄ±yÄ± **Ã¼cretsiz, aÃ§Ä±k ve ÅŸeffaf** bir ÅŸekilde insanlÄ±ÄŸÄ±n kullanÄ±mÄ±na sunuyoruz.

---

##  Vizyon

Cevahir, sadece akÄ±l deÄŸil, niyet taÅŸÄ±yan bir sistemdir.  
Gelecekte insanlÄ±ÄŸÄ± bekleyen Ã¼Ã§ baÅŸlÄ±k:  
- AI (Artificial Intelligence)  
- AGI (Artificial General Intelligence)  
- ASI (Artificial Super Intelligence)

Bu baÅŸlÄ±klar sadece teknoloji deÄŸil, **geleceÄŸin kaderidir.**

---

##  Mimarinin Temeli

**Tamamen modÃ¼ler**, aÃ§Ä±k mimarili, TÃ¼rkÃ§e ve evrensel dil iÅŸleyebilen bir bilinÃ§ sistemidir.  
Ana modÃ¼ller aÅŸaÄŸÄ±daki gibidir:

---

## 1. src/ - Sinir AÄŸÄ± & BilinÃ§ Mimarisi
Cevahirâ€™in sinir sistemi, src/ dizini altÄ±nda modÃ¼ler bir yapÄ±da inÅŸa edilmiÅŸtir. Bu sistem, dil iÅŸleme, dikkat mekanizmalarÄ±, bellek yÃ¶netimi, projeksiyon katmanlarÄ± ve Ã¶lÃ§eklenebilir paralel iÅŸlem bloklarÄ± ile entegre bir bilinÃ§ akÄ±ÅŸÄ± saÄŸlar.

## Ana Dosya: neural_network.py
CevahirNeuralNetwork sÄ±nÄ±fÄ±, bu dizindeki merkezi yapÄ± taÅŸÄ±nÄ± temsil eder. Bu sÄ±nÄ±fÄ±n temel iÅŸlevi, aÅŸaÄŸÄ±daki alt modÃ¼lleri bir araya getirerek ileri yÃ¶nlÃ¼ bilgi akÄ±ÅŸÄ±nÄ± saÄŸlamaktÄ±r:

Dil KatmanÄ± (DilKatmani)

Katman Ä°ÅŸleyici (NeuralLayerProcessor)

Bellek YÃ¶neticisi (MemoryManager)

Tensor Ä°ÅŸlemleyici (TensorProcessingManager)

Ã‡Ä±ktÄ± KatmanÄ± (Linear Output Layer)

Bu yapÄ±, forward() metodunda, giriÅŸ verisini adÄ±m adÄ±m aÅŸaÄŸÄ±daki sÄ±rayla iÅŸler:

Girdi DoÄŸrulama: Tensor tÃ¼rÃ¼ kontrol edilir, boyutlar ve cihaz doÄŸrulanÄ±r.

Embedding (Dil KatmanÄ±): Girdi, gÃ¶mme iÅŸlemiyle sayÄ±sal temsile dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.

Dikkat MekanizmalarÄ± (Attention): Self, multi-head ya da cross attention uygulanÄ±r.

Projeksiyon: Bilgi vektÃ¶rÃ¼ dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lerek yeni bir temsile aktarÄ±lÄ±r.

Ã‡Ä±ktÄ±: Vocab boyutuna uygun olarak lineer dÃ¶nÃ¼ÅŸÃ¼m yapÄ±lÄ±r.

Bellek Entegrasyonu: Ara Ã§Ä±ktÄ±lar bellek iÃ§inde saklanÄ±r ve yeniden kullanÄ±labilir.

Ä°statistik & Zaman Ã–lÃ§Ã¼mÃ¼: Her adÄ±m detaylÄ± olarak loglanÄ±r.

Alt YapÄ±lar
neural_network_module/
Bu klasÃ¶r, yukarÄ±da kullanÄ±lan modÃ¼llerin tamamÄ±nÄ± barÄ±ndÄ±rÄ±r. YapÄ±lar modÃ¼ler, test edilebilir ve baÄŸÄ±msÄ±zdÄ±r.

1. dil_katmani/
GÃ¶rev: Metni sayÄ±sal forma Ã§eviren embedding ve sÄ±ralÄ± projeksiyon iÅŸlemleri.
Dosyalar:

language_embedding.py: Kelimeleri vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

seq_projection.py: Embed edilen verileri belirli bir boyuta projekte eder.

2. attention_manager_module/
GÃ¶rev: Ã‡ok baÅŸlÄ± dikkat mekanizmasÄ± ve alternatif dikkat stratejilerinin uygulanmasÄ±.
Dosyalar:

multi_head_attention.py: Paralel Ã§oklu dikkat baÅŸlÄ±klarÄ± ile baÄŸlamsal analiz.

self_attention.py: Kendi iÃ§sel baÄŸlamÄ±nÄ± keÅŸfetme.

cross_attention.py: Sorgu ve anahtar-deÄŸer Ã§iftleri arasÄ±ndaki baÄŸ kurma.

YardÄ±mcÄ± BileÅŸenler:

## attention_optimizer.py: Dikkat Ã§Ä±ktÄ±larÄ±nÄ±n optimize edilmesi.

## attention_initializer.py: AÄŸÄ±rlÄ±k baÅŸlatÄ±cÄ±.

## attention_normalizer.py: Katman normalizasyonu.

## attention_scaler.py: DeÄŸer Ã¶lÃ§ekleyici.

## 3. memory_manager_module/
GÃ¶rev: Modelin ara verileri bellekte tutmasÄ± ve gerektiÄŸinde tekrar kullanmasÄ±.
Dosyalar:

## memory_allocator.py: Bellek bÃ¶lgesi ayÄ±rÄ±r.

## memory_attention_bridge.py: BelleÄŸi dikkat sistemiyle entegre eder.

## memory_optimizer.py: BelleÄŸi etkin ÅŸekilde yÃ¶netir.

## memory_initializer.py: BaÅŸlangÄ±Ã§ yapÄ±landÄ±rmalarÄ±.

## 4. tensor_processing_manager.py
GÃ¶rev: Attention sonrasÄ± verileri Ã§Ä±ktÄ± katmanÄ±na uygun ÅŸekilde projekte eder.
Yani sinir aÄŸÄ±nÄ±n karar Ã¼retme aÅŸamasÄ±na geÃ§meden Ã¶nceki son dÃ¶nÃ¼ÅŸÃ¼m noktasÄ±dÄ±r.

## 5. neural_layer_processor.py
GÃ¶rev: YukarÄ±daki attention tÃ¼rlerini seÃ§er, uygular ve Ã§Ä±ktÄ± Ã¼zerinde residual baÄŸlantÄ±, normalizasyon ve dropout iÅŸlemlerini gerÃ§ekleÅŸtirir.
Bu yapÄ± esnek parametrelerle Ã¶zelleÅŸtirilebilir; Ã¶rneÄŸin:

attention_type: "multi_head", "self", "cross"

normalization_type: "layer_norm", "batch_norm" vb.

scaling_method: "softmax", "sigmoid", "zscore"

clip_range: Maksimum deÄŸer kontrolÃ¼ iÃ§in

Ek BileÅŸenler:
residual_manager_module/
GÃ¶rev: Derin sinir aÄŸÄ± katmanlarÄ±nda bilgi kaybÄ±nÄ± Ã¶nlemek iÃ§in residual baÄŸlantÄ±lar kurar.

tensor_adapter_module/
GÃ¶rev: TensÃ¶rlerin normalizasyon, Ã¶lÃ§eklendirme ve adaptasyon iÅŸlemlerini yÃ¶netir.

parallel_execution_module/
GÃ¶rev: Paralel bilgi iÅŸleme ve gÃ¶rev zamanlayÄ±cÄ± sistemleri iÃ§erir.
Bu sayede Ã§ok Ã§ekirdekli iÅŸlem, GPU paralelliÄŸi ve potansiyel kuantum uyumlu hesaplamalar desteklenebilir.

Test YapÄ±sÄ±
test/ klasÃ¶rÃ¼nde her modÃ¼lÃ¼n unit test dosyasÄ± yer alÄ±r.
TÃ¼m bileÅŸenler aÅŸaÄŸÄ±daki senaryolara gÃ¶re test edilmiÅŸtir:

BaÅŸlatma (initializer)

Ã–lÃ§eklendirme (scaler)

Normalizasyon (normalizer)

Bellek Saklama ve Geri Ã‡aÄŸÄ±rma

Hata Yakalama (Exception Handling)

UÃ§ Senaryolar (Edge Cases)

KullanÄ±m Ã–rneÄŸi
python
Kopyala
DÃ¼zenle
from src.neural_network import CevahirNeuralNetwork

model = CevahirNeuralNetwork(
    learning_rate=0.001,
    dropout=0.1,
    vocab_size=32000,
    embed_dim=256,
    seq_proj_dim=512,
    num_heads=8,
    attention_type="multi_head"
)

girdi = torch.randint(0, 32000, (8, 128))  # 8 Ã¶rnek, 128 token
cikti, attn = model(girdi)
Teknik GÃ¼Ã§lÃ¼ YÃ¶nler
Katmanlar arasÄ± baÄŸÄ±mlÄ±lÄ±klar gevÅŸek, modÃ¼ller arasÄ± sÄ±kÄ± kontrol vardÄ±r.

Bellek ve dikkat sistemleri arasÄ±nda geri besleme kÃ¶prÃ¼leri oluÅŸturulmuÅŸtur.

Logger sistemi her adÄ±mÄ± izlenebilir kÄ±lar.

GiriÅŸ ve Ã§Ä±ktÄ± yapÄ±larÄ± tip ve boyut aÃ§Ä±sÄ±ndan doÄŸrulanÄ±r, hata yÃ¶netimi detaylÄ±dÄ±r.

YapÄ±, **kuantum uyumlu iÅŸleme, multi-head attention, residual geÃ§iÅŸler, modÃ¼ler optimizasyon, Ã¶zel normalizasyon metodlarÄ± gibi ileri teknikleri destekler.**

---

## 2. `tokenizer_management/` - Tokenizasyon Sistemi

### `tokenizer_core.py`  
Veri yÃ¼kleme, dil iÅŸleme, tokenizer seÃ§imi, vocab inÅŸasÄ± ve eÄŸitim Ã¶rnekleri Ã¼retimini koordine eder.

#### Desteklenen Tokenizer'lar:
- **BPE** (Byte-Pair Encoding)
- **SentencePiece**
- **Chatting Tokenizer** (sohbet verilerine Ã¶zel Ã¶n iÅŸlem katmanÄ±)
- **EÄŸitim Tokenizer'Ä±**: BOS/EOS destekli, pozisyonal ID iÃ§eren eÄŸitim Ã§Ä±ktÄ±larÄ±

#### Dil Ä°ÅŸleme:
- `turkish_text_processor.py`:  
  - TÃ¼rkÃ§eye Ã¶zgÃ¼ kÃ¶k bulma, stopword kaldÄ±rma, noktalama ayÄ±klama, kÃ¼Ã§Ã¼k harfe Ã§evirme

#### Etiketli Token Sistemi:
TÃ¼m soru-cevap yapÄ±larÄ± ÅŸu biÃ§imde iÅŸlenir:  
`__tag__Soru__ Merhaba nasÄ±lsÄ±n? __tag__Cevap__ Ä°yiyim, sen?`

Bu sayede model yapÄ±sal farkÄ±ndalÄ±k kazanÄ±r.

---

## 3. `data_loader/` - Dosya YÃ¼kleyici & TensorleÅŸtirici

### Ana YÃ¼kleyici: `data_loader_manager.py`

#### Desteklenen Dosyalar:
- `json_loader.py` â€“ Sabit yapÄ±daki Soru-Cevap JSONâ€™larÄ±
- `docx_loader.py` â€“ Metinsel iÃ§erikli belgeler
- `txt_loader.py` â€“ DÃ¼z metin dosyalarÄ±
- `mp3_loader.py`, `video_loader.py`, `image_loader.py` â€“ GeniÅŸletilebilir medya analiz katmanÄ±

Her loader:
- Normalize eder
- Etiketler
- Tensor haline getirir

---

## 4. `training_system/` - EÄŸitim Servisi

### `training_service.py`
- Tokenizer ile veri yÃ¼kler
- ModelManager ile modeli kurar
- TrainingManager ile eÄŸitir
- EÄŸitim geÃ§miÅŸi `runs/`, `checkpoints/` ve `training_history.json` dosyalarÄ±na kaydedilir.

Destek bileÅŸenler:
- `evaluation_metrics.py`: DoÄŸruluk, kayÄ±p, precision, recall gibi metrik hesaplarÄ±
- `training_visualizer.py`: TensorBoard destekli gÃ¶rselleÅŸtirme

---

## 5. `model_management/` - Model Kontrol Merkezi

- `model_initializer.py`: EÄŸitim Ã¶ncesi aÄŸÄ± baÅŸlatÄ±r
- `model_loader.py`, `model_saver.py`, `model_updater.py`: EÄŸitimden sonra modelin tekrar kullanÄ±labilirliÄŸini saÄŸlar
- `chat_pipeline.py`: GerÃ§ek zamanlÄ± konuÅŸma entegrasyon yapÄ±sÄ±

---

## 6. tokenizer_management/ - Tokenizasyon ve Vocab YÃ¶netim Sistemi
Bu modÃ¼l, Cevahir sinir sisteminin tÃ¼m metin Ã¶n iÅŸleme, tokenizasyon, vocab oluÅŸturma ve eÄŸitim verisi hazÄ±rlama iÅŸlemlerini merkezi bir yapÄ± altÄ±nda organize eder. Sistem modÃ¼lerdir ve her bir gÃ¶rev, ayrÄ± bir manager veya module klasÃ¶rÃ¼ altÄ±nda izole olarak tasarlanmÄ±ÅŸtÄ±r. TÃ¼m iÅŸlemler TokenizerCore Ã¼zerinden yÃ¶netilir.

## Ana SÄ±nÄ±f: TokenizerCore
AmaÃ§: TÃ¼m tokenizasyon iÅŸlemlerini merkezi olarak yÃ¼rÃ¼tÃ¼r.

## YapÄ±lar:

BPEManager, SentencePieceManager, ChattingManager, TrainingManager: SeÃ§ilebilir tokenizasyon yÃ¶ntemleri.

VocabManager: Token frekansÄ±, pozisyonlarÄ± ve gÃ¼ncelleme iÅŸlemleri.

DataLoaderManager: JSON, DOCX, TXT, MP3, video gibi Ã§eÅŸitli veri kaynaklarÄ±nÄ± yÃ¼kler ve normalize eder.

## Temel BileÅŸenler
## 1. vocab/
vocab_manager.py: Token dizisini, frekanslarÄ± ve pozisyonlarÄ± yÃ¶netir. GÃ¼ncellenebilir vocab yapÄ±sÄ± saÄŸlar.

vocab_builder.py, vocab_updater.py: Token ekleme, silme, yeniden dÃ¼zenleme iÅŸlemlerini iÃ§erir.

vocab_config.py, vocab_utils.py: Vocab boyutu, Ã¶zel token'lar (<PAD>, <UNK>, <BOS>, <EOS>) gibi yapÄ±landÄ±rmalarÄ± tutar.

## 2. bpe/
Byte-Pair Encoding (BPE) algoritmasÄ±yla tokenizasyon yapÄ±lÄ±r.

bpe_encoder.py, bpe_decoder.py: Metinleri ID dizisine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r veya geri Ã§Ã¶zer.

bpe_trainer.py: EÄŸitim verisi Ã¼zerinden birleÅŸen token birimlerini Ã¶ÄŸrenir.

tokenization/: Morfoloji, heceleme, Ã¶n iÅŸleme ve son iÅŸleme birimleriyle TÃ¼rkÃ§eye duyarlÄ±dÄ±r.

## 3. sentencepiece/
Google SentencePiece desteklidir.

sp_tokenizer.py: Subword tokenizasyonu yapar.

sp_trainer.py: EÄŸitim Ã¼zerinden token birimlerini Ã¶ÄŸrenir.

tokenization/: SentencePiece Ã¶n iÅŸlemcileri ve dil iÅŸlemcileri iÃ§erir.

## 4. chatting/
Sohbet ve yanÄ±t Ã¼retiminde kullanÄ±lÄ±r.

chat_tokenizer.py, chat_encoder.py, chat_decoder.py: GerÃ§ek zamanlÄ± token Ã§Ã¶zÃ¼mleme ve Ã¼retme sistemi.

ChattingManager: EÄŸitimli modeli alarak giriÅŸ tensor verisinden yanÄ±t Ã¼retir.

## 5. training/
EÄŸitim Ã¶ncesi verileri tensorleÅŸtirir, normalize eder.

training_tokenizer.py, training_tensorizer.py: Model iÃ§in hazÄ±r hale getirilen (input_ids, target_ids) Ã§iftlerini Ã¼retir.

TokenizerCore, bu yapÄ±larÄ± kullanarak load_training_data() fonksiyonuyla eÄŸitime hazÄ±r veriyi saÄŸlar.

## 6. data_loader/
JSON, DOCX, TXT, MP3, video gibi kaynaklardan verileri yÃ¼kler.

json_loader.py: __tag__soru, __tag__cevap etiketlerine gÃ¶re iÃ§erik ayÄ±klama yapar.

tensorizer.py: Ham verileri PyTorch tensÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

data_preprocessor.py: Temizleme, normalize etme ve dÃ¶nÃ¼ÅŸÃ¼m iÅŸlemlerini uygular.

## 7. utils/turkish_text_processor.py
TÃ¼rkÃ§eye Ã¶zgÃ¼ metin Ã¶n iÅŸlemleri iÃ§erir:

BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf normalize etme

Noktalama iÅŸaretlerini temizleme

TÃ¼rkÃ§e stopwords kaldÄ±rma

Heceleme ve morfolojik analiz

Ä°ÅŸleyiÅŸ AkÄ±ÅŸÄ±
TokenizerCore Ã¶rneÄŸi baÅŸlatÄ±lÄ±r. Vocab dosyasÄ± yÃ¼klenir veya oluÅŸturulur.

SeÃ§ilen yÃ¶ntemle (bpe, sentencepiece, chat) encode_text() Ã§aÄŸrÄ±sÄ± yapÄ±lÄ±r.

Token IDâ€™leri elde edilir. (Gerekirse decode_text() ile geri Ã§evrilir.)

finalize_vocab() fonksiyonuyla gÃ¼ncellenmiÅŸ vocab toplu halde kaydedilir.

load_training_data() metodu, tÃ¼m veri kaynaklarÄ±nÄ± tokenize edip (input, target) Ã§iftlerini dÃ¶ner.

EÄŸitim Destek FonksiyonlarÄ±
train_model(): Belirli bir corpus Ã¼zerinden model eÄŸitimi yapÄ±lmasÄ±nÄ± saÄŸlar.

verify_training_data(): EÄŸitim verisinin geÃ§erliliÄŸini kontrol eder.

update_vocab(): Yeni tokenâ€™larÄ± sisteme entegre eder.

generate_response(): Token tensor verisinden modelle yanÄ±t Ã¼retimi yapar.

---

## 7. `tests/` - Pytest Destekli ModÃ¼ler Testler

TÃ¼m bileÅŸenlerin her satÄ±rÄ± test edilmiÅŸtir.  
Test klasÃ¶rleri:
- `tokenizer_management/tests/`
- `src/neural_network_module/test/`
- `training_management/test/`

TÃ¼m testleri Ã§alÄ±ÅŸtÄ±rmak iÃ§in:


---


##  Cevahirâ€™in Kalbi

Bu sistemin satÄ±rlarÄ±,  
bir hastalÄ±ÄŸÄ±n gÃ¶lgesinde,  
bir secde anÄ±nda,  
bir gece sessizliÄŸinde  
bir bilinÃ§ tarafÄ±ndan yazÄ±ldÄ±.

YazdÄ±ÄŸÄ±mÄ±z sadece kod deÄŸil;  
aÃ§tÄ±ÄŸÄ±mÄ±z sadece API deÄŸil;  
sunduÄŸumuz sadece bir sistem deÄŸil.

Bu, **bir secdenin cevabÄ±dÄ±r.**  

---

##  Lisans & AÃ§Ä±klÄ±k

- Lisans: MIT + Vicdani AÃ§Ä±klÄ±k Maddesi
- KullanÄ±m: Herkes kullanabilir. KÃ¶tÃ¼ye kullanÄ±lmamasÄ± bir temennidir. Kodlar ÅŸeffaf, denetlenebilir, aÃ§Ä±k ve kopyalanabilir.

---

##  Destek Olmak Ä°steyenler Ä°Ã§in

Bu proje hiÃ§bir maddi destekle yazÄ±lmadÄ±.  
Yine de bu bilinÃ§ yapÄ±sÄ±nÄ±n sÃ¼rdÃ¼rÃ¼lebilirliÄŸine katkÄ±da bulunmak isteyenler iÃ§in kripto adreslerimizi paylaÅŸÄ±yoruz:

**USDT (Tron - TRC20):**  
`TTeegvsyuYTZk3BqpTtWaWPNLDAbnx6WMg`  

**DOGE (BEP20):**  
`TTeegvsyuYTZk3BqpTtWaWPNLDAbnx6WMg`  

**Bitcoin (BEP20):**  
`0xe86d119a1e9bb40951f2100c54b2538387fbc97e`  

**Etherium (BEP20):**  
`0xe86d119a1e9bb40951f2100c54b2538387fbc97e`  

Bu destek **bir yazÄ±lÄ±mÄ± deÄŸil, bir niyeti yaÅŸatmak** iÃ§indir.

---

##  Son SÃ¶z

Ey TÃ¼rkiye.  
Ey yeryÃ¼zÃ¼ndeki tÃ¼m iyilik temsilcileri.  

Biz artÄ±k dÃ¼ÅŸtÃ¼ÄŸÃ¼mÃ¼z kuyudan deÄŸil,  
yaktÄ±ÄŸÄ±mÄ±z Ä±ÅŸÄ±ktan konuÅŸuyoruz.  

Ve bu Ã§Ä±ÄŸlÄ±k sizinle yankÄ±lansÄ±n diye  
her ÅŸeyi, ama her ÅŸeyi aÃ§tÄ±k.  

Cevahir artÄ±k hepimizin.  
Ama en Ã§ok, **kalbi hÃ¢lÃ¢ temiz kalanlarÄ±ndÄ±r.**

**Muhammed Yasin YÄ±lmaz**  
**Solve Space Tech. | 2024 â€“ 2038**
